{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data please wait will take around a minute\n",
      "Data loading completed\n"
     ]
    }
   ],
   "source": [
    "Data,Labels = sf.data_loader_mnist.load_normalized_mnist_data_flat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simflow as sf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sf.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dim=784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_layer(sf.layers.Dense(inp_dim,200))\n",
    "net.add_layer(sf.layers.ReLU())\n",
    "net.add_layer(sf.layers.Dense(200,10))\n",
    "net.set_loss_fn(sf.losses.SoftmaxCrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.set_optimizer(SGD(lr=0.001,momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.set_iterator(sf.iterators.minibatch_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0, average train loss: 0.024\n",
      "Train:  0.08448 validation:  0.0804 test:  0.0809\n",
      "Epoch:   0, average train loss: 0.024\n",
      "Train:  0.08448 validation:  0.0804 test:  0.0809\n",
      "Epoch:   0, average train loss: 0.024\n",
      "Train:  0.08448 validation:  0.0804 test:  0.0809\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    net.fit(Data['train'],Labels['train'],epochs=1)\n",
    "    print(\"Train: \",net.score(Data['train'],Labels['train'])[1],end=\" \")\n",
    "    print(\"validation: \",net.score(Data['val'],Labels['val'])[1],end =' ')\n",
    "    print(\"test: \",net.score(Data['test'],Labels['test'])[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0, average train loss: 0.005\n",
      "Train:  0.8963 validation:  0.9068 test:  0.9\n",
      "Epoch:   0, average train loss: 0.003\n",
      "Train:  0.91646 validation:  0.9209 test:  0.9179\n",
      "Epoch:   0, average train loss: 0.002\n",
      "Train:  0.9267 validation:  0.9309 test:  0.9276\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    net.fit(Data['train'],Labels['train'],epochs=1)\n",
    "    print(\"Train: \",net.score(Data['train'],Labels['train'])[1],end=\" \")\n",
    "    print(\"validation: \",net.score(Data['val'],Labels['val'])[1],end =' ')\n",
    "    print(\"test: \",net.score(Data['test'],Labels['test'])[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.optimizer.m_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(sf.optimizers.Optimizer):\n",
    "    def __init__(self,lr=0.01,momentum=0,decay=0,nestrov=False,**kwargs):\n",
    "        super(SGD,self).__init__(**kwargs)\n",
    "        assert momentum>=0,\"-ve momentum not valid\"\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.decay = decay\n",
    "        self.nestrov = nestrov\n",
    "        self.iter = 0\n",
    "\n",
    "    def update_step(self,vars_and_grads):\n",
    "        params,grads = self.get_var_and_grads(vars_and_grads)\n",
    "        if not hasattr(self,'m_grads') and self.momentum:\n",
    "            #for the first time we need  to init m_grads with zeros\n",
    "            self.m_grads = [np.zeros_like(g) for g in grads]\n",
    "        self.iter+=1\n",
    "        lr = self.lr\n",
    "        lr *= (1/(1+self.decay*self.iter))\n",
    "\n",
    "        if self.momentum:\n",
    "            for p,g,m in zip(params,grads,self.m_grads):\n",
    "                m *= self.momentum\n",
    "                m -= (lr * g)\n",
    "                if self.nestrov:\n",
    "                    p += self.momentum*m - lr*g\n",
    "                else:\n",
    "                    p += m\n",
    "        else:\n",
    "            for p,g in zip(params,grads):\n",
    "                p -= lr*g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
